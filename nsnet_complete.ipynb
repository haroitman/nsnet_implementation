{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras.backend as K\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas import DataFrame\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean speech, Noise and Noisy speech training files\n",
    "# Count how many samples of Clean speech are used for training and how many snr levels, \n",
    "# there are snr levels of Noise and Noisy speech for every Clean speech audio\n",
    "clean_speech_list = [f for f in listdir(\"CleanSpeech_training/\") if isfile(join(\"CleanSpeech_training/\", f))]\n",
    "noise_list = [f for f in listdir(\"Noise_training/\") if isfile(join(\"Noise_training/\", f))]\n",
    "noisy_speech_list = [f for f in listdir(\"NoisySpeech_training/\") if isfile(join(\"NoisySpeech_training/\", f))]\n",
    "samples = len(clean_speech_list)\n",
    "snr_levels = len(noisy_speech_list) / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick randonmly one of the snr level of the Noise and Noisy speech samples \n",
    "from random import seed\n",
    "from random import randint\n",
    "seed(1)\n",
    "random_snr = np.random.randint(1, snr_levels+1, size=samples)\n",
    "for i in range(0,samples):\n",
    "    random_snr[i] = random_snr[i] + ((i) * snr_levels)\n",
    "random_snr = random_snr - 1\n",
    "random_snr = random_snr.astype(np.int64)\n",
    "\n",
    "rand_noisy_speech_list = list(noisy_speech_list[i] for i in random_snr)\n",
    "rand_noise_list = list(noise_list[i] for i in random_snr)\n",
    "noisy_speech_df = DataFrame(rand_noisy_speech_list,columns=['Sample'])\n",
    "noise_df = DataFrame(rand_noise_list,columns=['Sample'])\n",
    "clean_speech_df = DataFrame(clean_speech_list, columns=[\"Sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: noisy10_SNRdb_20.0_clnsp10.wav \n",
    "# List maximum possible elements is 99,999  \n",
    "noisy_speech_aux_list = [x[-9:-4] for x in noisy_speech_df[\"Sample\"]]\n",
    "sample_column = noisy_speech_aux_list\n",
    "for i in range(0,len(noisy_speech_aux_list)):\n",
    "    try:\n",
    "        sample_column[i] = int(noisy_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            sample_column[i] = int(noisy_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                sample_column[i] = int(noisy_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    sample_column[i] = int(noisy_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        sample_column[i] = int(noisy_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the df by sample_column number\n",
    "# Noise has the same file formatting than Noisy speech so it is sorted using the same df column\n",
    "noisy_speech_df[\"Sample_Number\"] = sample_column\n",
    "noise_df[\"Sample_Number\"] = sample_column\n",
    "noisy_speech_df.sort_values(by=['Sample_Number'], inplace=True)\n",
    "noise_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: clnsp1.wav\n",
    "# List maximum possible elements is 99,999\n",
    "clean_speech_aux_list = [x[-9:-4] for x in clean_speech_df[\"Sample\"]]\n",
    "clean_speach_sample_number = clean_speech_aux_list\n",
    "for i in range(0,len(clean_speech_aux_list)):\n",
    "    try:\n",
    "        clean_speach_sample_number[i] = int(clean_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order clean speech df by sample_column number\n",
    "clean_speech_df[\"Sample_Number\"] = clean_speach_sample_number\n",
    "clean_speech_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lists based on the data frames\n",
    "clean_speech_ordered_list = clean_speech_df[\"Sample\"]\n",
    "noisy_speech_ordered_list = noisy_speech_df[\"Sample\"]\n",
    "noise_ordered_list = noise_df['Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"CleanSpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "clean_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\CleanSpeech_training\\\\'+item for item in clean_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"NoisySpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noisy_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\NoisySpeech_training\\\\'+item for item in noisy_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"Noise_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noise_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\Noise_training\\\\'+item for item in noise_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio files as floating point time series\n",
    "clean_speech_wave = np.zeros((len(clean_speech_ordered_list), 500000))\n",
    "i = 0\n",
    "for y in clean_speech_ordered_list: \n",
    "    wave, sr = librosa.load(y, sr = 16000,mono = True)\n",
    "    clean_speech_wave[i,:len(wave)] = wave\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Short Time Fourier Transform of each audio wave \n",
    "# First clean_samples_wave is used to find the stft dimensions\n",
    "# STFT is reduced to 160 frames, equal to 5sec sample\n",
    "f, t, z = scipy.signal.stft(clean_speech_wave[0,:], fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "clean_speech_frequency = np.zeros((f.shape[0],clean_speech_wave.shape[0]))\n",
    "clean_speech_time = np.zeros((t.shape[0],clean_speech_wave.shape[0]))\n",
    "clean_speech_zxx = np.zeros((f.shape[0],t.shape[0],clean_speech_wave.shape[0]), dtype=complex)\n",
    "for i in (0,clean_speech_wave.shape[0]-1):\n",
    "    f, t, z  = scipy.signal.stft(clean_speech_wave[i,:], fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "    clean_speech_frequency[:,i] = f\n",
    "    clean_speech_time[:,i] = t\n",
    "    clean_speech_zxx[:,:,i] = z\n",
    "clean_speech_time = clean_speech_time[:160]\n",
    "clean_speech_zxx = clean_speech_zxx[:,:160,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio files as floating point time series\n",
    "noisy_speech_wave = np.zeros((len(noisy_speech_ordered_list), 500000))\n",
    "i = 0\n",
    "for y in noisy_speech_ordered_list: \n",
    "    wave, sr = librosa.load(y, sr = 16000,mono = True)\n",
    "    noisy_speech_wave[i,:len(wave)] = wave\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Short Time Fourier Transform of each audio wave \n",
    "# First clean_samples_wave is used to find the stft dimensions\n",
    "# STFT is reduced to 160 frames, equal to 5sec sample\n",
    "f, t, z = scipy.signal.stft(noisy_speech_wave[0,:], fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "noisy_speech_frequency = np.zeros((f.shape[0],noisy_speech_wave.shape[0]))\n",
    "noisy_speech_time = np.zeros((t.shape[0],noisy_speech_wave.shape[0]))\n",
    "noisy_speech_zxx = np.zeros((f.shape[0],t.shape[0],noisy_speech_wave.shape[0]), dtype=complex)\n",
    "for i in (0,noisy_speech_wave.shape[0]-1):\n",
    "    f, t, z  = scipy.signal.stft(noisy_speech_wave[i,:], fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "    noisy_speech_frequency[:,i] = f\n",
    "    noisy_speech_time[:,i] = t\n",
    "    noisy_speech_zxx[:,:,i] = z\n",
    "noisy_speech_time = noisy_speech_time[:160]\n",
    "noisy_speech_zxx = noisy_speech_zxx[:,:160,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio files as floating point time series\n",
    "noise_wave = np.zeros((len(noise_ordered_list), 500000))\n",
    "i = 0\n",
    "for y in noise_ordered_list: \n",
    "    wave, sr = librosa.load(y, sr = 16000,mono = True)\n",
    "    noise_wave[i,:len(wave)] = wave\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Short Time Fourier Transform of each audio wave \n",
    "# First clean_samples_wave is used to find the stft dimensions\n",
    "# STFT is reduced to 160 frames, equal to 5sec sample\n",
    "f, t, z = scipy.signal.stft(noise_wave[0,:], fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "noise_frequency = np.zeros((f.shape[0],noise_wave.shape[0]))\n",
    "noise_time = np.zeros((t.shape[0],noise_wave.shape[0]))\n",
    "noise_zxx = np.zeros((f.shape[0],t.shape[0],noise_wave.shape[0]), dtype=complex)\n",
    "for i in (0,noise_wave.shape[0]-1):\n",
    "    f, t, z  = scipy.signal.stft(noise_wave[i,:], fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "    noise_frequency[:,i] = f\n",
    "    noise_time[:,i] = t\n",
    "    noise_zxx[:,:,i] = z\n",
    "noise_time = noise_time[:160]\n",
    "noise_zxx = noise_zxx[:,:160,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Independent Normalization\n",
    "noisy_speech_zxx_mean_fi = np.mean(noisy_speech_zxx)    \n",
    "noisy_speech_zxx_std_fi = np.std(noisy_speech_zxx)\n",
    "noisy_speech_normalized_fi = (noisy_speech_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi\n",
    "noise_normalized_fi = (noise_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi\n",
    "clean_speech_normalized_fi = (clean_speech_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voice Activity Detector (VAD) based on accumulated energy (measured in db) for frequencies between 300Hz and 5000Hz\n",
    "\n",
    "# Calculate acumulated energy (db) for each frame of each audio\n",
    "vad_min_frequency_limit = 300\n",
    "vad_max_frequency_limit = 5000\n",
    "clean_speech_zxx_db = -librosa.amplitude_to_db(np.abs(clean_speech_zxx), ref=np.max)\n",
    "acumulated_energy_db = np.zeros((clean_speech_zxx.shape[1],clean_speech_zxx.shape[2]))\n",
    "for s in range(0,clean_speech_frequency.shape[1]):\n",
    "    for f in range(0,clean_speech_frequency.shape[0]):\n",
    "        if clean_speech_frequency[f,s] > vad_min_frequency_limit and clean_speech_frequency[f,s] < vad_max_frequency_limit:\n",
    "            for j in range(0,clean_speech_zxx.shape[1]-1):\n",
    "                acumulated_energy_db[j,s] = acumulated_energy_db[j,s] + clean_speech_zxx_db[f,j,s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the acumulated energy over 3 frames\n",
    "smooth_energy_db = np.zeros((acumulated_energy_db.shape))\n",
    "smooth_energy_db[0,:] = acumulated_energy_db[0,:]\n",
    "smooth_energy_db[acumulated_energy_db.shape[0]-1,:] = acumulated_energy_db[acumulated_energy_db.shape[0]-1,:]\n",
    "for j in range(1,acumulated_energy_db.shape[0]-2):\n",
    "    smooth_energy_db[j,:] = (acumulated_energy_db[j-1,:] + acumulated_energy_db[j,:] + acumulated_energy_db[j+1,:]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a matrix [0,1] for frames with an accumulated energy above (Max - threshold)\n",
    "treshold_db = 1000\n",
    "max_smooth_energy_db = smooth_energy_db.max(axis=0)\n",
    "frame_bin = np.zeros((smooth_energy_db.shape))\n",
    "for j in range (0, acumulated_energy_db.shape[0]):\n",
    "    frame_bin[j,:] = np.where(smooth_energy_db[j,:] > max_smooth_energy_db[:] - treshold_db, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make zero the frames below the threshold\n",
    "zxx_bin = np.repeat(np.expand_dims(frame_bin, axis=0), 257, 0)\n",
    "vad_clean_speech_normalized_fi = clean_speech_normalized_fi * zxx_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "\n",
    "x = layers.Input(shape=(160,257))\n",
    "cell = layers.GRU(257, batch_input_shape=(12,160,257), return_sequences=True)(x)\n",
    "cell_residual = layers.add([x, cell])\n",
    "cell = layers.GRU(257, batch_input_shape=(12,160), return_sequences=True)(cell_residual)\n",
    "cell_residual = layers.add([cell_residual, cell])\n",
    "cell = layers.GRU(257, batch_input_shape=(12, 160), return_sequences=True)(cell_residual)\n",
    "cell = layers.Dense(257, activation='sigmoid')(cell)\n",
    "model = tf.keras.Model(inputs=x, outputs=cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter alfa (0,1) is the weight between audio distortion and noise cancellation (1-alfa) \n",
    "alfa = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss\n",
    "def custom_loss(alfa, noise_normalized_fi):\n",
    "\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(vad_clean_speech_normalized_fi,vad_clean_speech_pred):\n",
    "        return alfa * K.mean(K.square(vad_clean_speech_normalized_fi - vad_clean_speech_pred), axis=-1) + (1-alfa) * np.mean(np.square(noise_normalized_fi), axix=-1)\n",
    "   \n",
    "    # Return a function\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "custom_loss() missing 1 required positional argument: 'noise_normalized_fi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-295-4aa99026352f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compile the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model.compile(optimizer='adam',\n\u001b[1;32m----> 3\u001b[1;33m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Call the loss function with the selected layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m               metrics=['accuracy'])   # use instead custom_loss\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: custom_loss() missing 1 required positional argument: 'noise_normalized_fi'"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=custom_loss(1), # Call the loss function with the selected layer\n",
    "              metrics=['accuracy'])   # use instead custom_loss\n",
    "\n",
    "# train\n",
    "model.fit(data, labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

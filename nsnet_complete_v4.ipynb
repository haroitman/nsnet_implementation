{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras.backend as K\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas import DataFrame\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean speech, Noise and Noisy speech training files\n",
    "# Count how many samples of Clean speech are used for training and how many snr levels, \n",
    "# there are snr levels of Noise and Noisy speech for every Clean speech audio\n",
    "clean_speech_list = [f for f in listdir(\"CleanSpeech_training/\") if isfile(join(\"CleanSpeech_training/\", f))]\n",
    "noise_list = [f for f in listdir(\"Noise_training/\") if isfile(join(\"Noise_training/\", f))]\n",
    "noisy_speech_list = [f for f in listdir(\"NoisySpeech_training/\") if isfile(join(\"NoisySpeech_training/\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy speech original 3701\n",
      "noisy speech complete 3696\n",
      "clean speech original 1237\n",
      "clean speech complete 1232\n",
      "noise original 3705\n",
      "noise complete 3696\n"
     ]
    }
   ],
   "source": [
    "## Make audios set complete\n",
    "\n",
    "#Erase duplicate audios\n",
    "\n",
    "clean_speech_list_complete = [item for item in clean_speech_list if item[-5:-4].isdigit()]\n",
    "noise_list_complete = [item for item in noise_list if item[-5:-4].isdigit()]\n",
    "\n",
    "noisy_speech_list_split = [item.split('_') for item in noisy_speech_list]\n",
    "df = pd.DataFrame(noisy_speech_list_split)\n",
    "df.columns = ['noisy','type','level','clean']\n",
    "df = df[df['clean'].apply(lambda x : x[-5:-4].isdigit())]\n",
    "\n",
    "#Get the noisy audios that match with clean and noise audios\n",
    "\n",
    "df['noisy_audio'] = (df['noisy'] + '_' + df['type'] + '_' + df['level'] + '_' + df['clean']).values\n",
    "df['noise_audio'] = (df['noisy'] + '_' + df['type'] + '_' + df['level'] + '.wav').values\n",
    "\n",
    "#Get the noisy audios that have 3 times the same clean audio reference\n",
    "\n",
    "df_grouped = df.groupby(['clean']).count()\n",
    "df_count = df_grouped[df_grouped['noisy']==3]\n",
    "clean_reference = [item for item in df_count.index]\n",
    "df = df[df['clean'].isin(clean_reference)]\n",
    "noise_reference = [item for item in df['noise_audio']]\n",
    "\n",
    "#Filter noise and clean audios according to references from noisy audios\n",
    "clean_speech_list_complete = [item for item in clean_speech_list_complete if item in clean_reference]\n",
    "noise_list_complete = [item for item in noise_list_complete if item in noise_reference]\n",
    "\n",
    "noisy_speech_list_complete = (df['noisy'] + '_' + df['type'] + '_' + df['level'] + '_' + df['clean']).values\n",
    "\n",
    "#Compare original vs complete audios\n",
    "\n",
    "print('noisy speech original {}'.format(len(noisy_speech_list)))\n",
    "print('noisy speech complete {}'.format(len(noisy_speech_list_complete)))\n",
    "print('clean speech original {}'.format(len(clean_speech_list)))\n",
    "print('clean speech complete {}'.format(len(clean_speech_list_complete)))\n",
    "print('noise original {}'.format(len(noise_list)))\n",
    "print('noise complete {}'.format(len(noise_list_complete)))\n",
    "\n",
    "#Update audios\n",
    "\n",
    "clean_speech_list = clean_speech_list_complete\n",
    "noise_list = noise_list_complete\n",
    "noisy_speech_list = noisy_speech_list_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = len(clean_speech_list)\n",
    "snr_levels = len(noisy_speech_list) / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16KHz audios assumed\n",
    "frames_per_sec = 32           # Number of frames per second\n",
    "sample_length = 30            # Sample length in seconds\n",
    "segment_length = 5            # Audio segment length in seconds considered in the network training   \n",
    "wave_max_length = 600000      # Number larger than the longest audio wave \n",
    "frames_per_sample = frames_per_sec * sample_length \n",
    "segment_frames_lenght = segment_length * frames_per_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick randonmly one of the snr level of the Noise and Noisy speech samples \n",
    "from random import seed\n",
    "from random import randint\n",
    "seed(1)\n",
    "random_snr = np.random.randint(1, snr_levels+1, size=samples)\n",
    "for i in range(samples):\n",
    "    random_snr[i] = random_snr[i] + ((i) * snr_levels)\n",
    "random_snr = random_snr - 1\n",
    "random_snr = random_snr.astype(np.int64)\n",
    "\n",
    "rand_noisy_speech_list = list(noisy_speech_list[i] for i in random_snr)\n",
    "rand_noise_list = list(noise_list[i] for i in random_snr)\n",
    "noisy_speech_df = DataFrame(rand_noisy_speech_list,columns=['Sample'])\n",
    "noise_df = DataFrame(rand_noise_list,columns=['Sample'])\n",
    "clean_speech_df = DataFrame(clean_speech_list, columns=[\"Sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: noisy10_SNRdb_20.0_clnsp10.wav \n",
    "# List maximum possible elements is 99,999  \n",
    "noisy_speech_aux_list = [x[-9:-4] for x in noisy_speech_df[\"Sample\"]]\n",
    "sample_column = noisy_speech_aux_list\n",
    "for i in range(len(noisy_speech_aux_list)):\n",
    "    try:\n",
    "        sample_column[i] = int(noisy_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            sample_column[i] = int(noisy_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                sample_column[i] = int(noisy_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    sample_column[i] = int(noisy_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        sample_column[i] = int(noisy_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the df by sample_column number\n",
    "# Noise has the same file formatting than Noisy speech so it is sorted using the same df column\n",
    "noisy_speech_df[\"Sample_Number\"] = sample_column\n",
    "noise_df[\"Sample_Number\"] = sample_column\n",
    "noisy_speech_df.sort_values(by=['Sample_Number'], inplace=True)\n",
    "noise_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: clnsp1.wav\n",
    "# List maximum possible elements is 99,999\n",
    "clean_speech_aux_list = [x[-9:-4] for x in clean_speech_df[\"Sample\"]]\n",
    "clean_speach_sample_number = clean_speech_aux_list\n",
    "for i in range(len(clean_speech_aux_list)):\n",
    "    try:\n",
    "        clean_speach_sample_number[i] = int(clean_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order clean speech df by sample_column number\n",
    "clean_speech_df[\"Sample_Number\"] = clean_speach_sample_number\n",
    "clean_speech_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lists based on the data frames\n",
    "clean_speech_ordered_list = clean_speech_df[\"Sample\"]\n",
    "noisy_speech_ordered_list = noisy_speech_df[\"Sample\"]\n",
    "noise_ordered_list = noise_df['Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"CleanSpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "clean_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\CleanSpeech_training\\\\'+item for item in clean_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"NoisySpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noisy_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\NoisySpeech_training\\\\'+item for item in noisy_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"Noise_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noise_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\Noise_training\\\\'+item for item in noise_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_function(audio):\n",
    "    # generate the wave of the audio sample\n",
    "    \n",
    "    wave, sr = librosa.load(audio, sr = 16000, mono = True)\n",
    "    f, t, stft  = scipy.signal.stft(wave, fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "    \n",
    "    return(stft, f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_independent_normalization(sample_number):\n",
    "    # Normalize noisy speech, clean speech and noise audios based on noisy speech global mean and standard deviation \n",
    "    # frequency independent\n",
    "    \n",
    "    noisy_speech_zxx, f, t =  wave_function(noisy_speech_ordered_list[sample_number])\n",
    "    noisy_speech_zxx_mean_fi = np.mean(noisy_speech_zxx)    \n",
    "    noisy_speech_zxx_std_fi = np.std(noisy_speech_zxx)\n",
    "    noisy_speech_normalized_fi = (noisy_speech_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi\n",
    "    \n",
    "    noise_zxx, f, t = wave_function(noise_ordered_list[sample_number])\n",
    "    noise_normalized_fi = (noise_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi\n",
    "    \n",
    "    clean_speech_zxx, f, t = wave_function(clean_speech_ordered_list[sample_number])\n",
    "    clean_speech_normalized_fi = (clean_speech_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi \n",
    "\n",
    "    return (noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vad(sample_number):\n",
    "    # Voice Activity Detector (VAD) based on accumulated energy (measured in db) for frequencies between 300Hz and 5000Hz\n",
    "    # Calculate acumulated energy (db) for each frame of each audio\n",
    "\n",
    "    vad_min_frequency_limit = 300\n",
    "    vad_max_frequency_limit = 5000\n",
    "    clean_speech_zxx, clean_speech_frequency, clean_speech_time = wave_function(clean_speech_ordered_list[sample_number])\n",
    "    clean_speech_zxx_db = -librosa.amplitude_to_db(np.abs(clean_speech_zxx))  # , ref=np.max\n",
    "    acumulated_energy_db = np.zeros((clean_speech_zxx.shape[1]))\n",
    "    for f in range(clean_speech_frequency.shape[0]):\n",
    "        if clean_speech_frequency[f] > vad_min_frequency_limit and clean_speech_frequency[f] < vad_max_frequency_limit:\n",
    "            for j in range(clean_speech_zxx.shape[1]):\n",
    "                    acumulated_energy_db[j] = acumulated_energy_db[j] + clean_speech_zxx_db[f,j] \n",
    "    \n",
    "    # Smooth the acumulated energy over 3 frames\n",
    "    smooth_energy_db = np.zeros((acumulated_energy_db.shape))\n",
    "    smooth_energy_db[0] = acumulated_energy_db[0]\n",
    "    smooth_energy_db[acumulated_energy_db.shape[0]-1] = acumulated_energy_db[acumulated_energy_db.shape[0]-1]\n",
    "    for j in range(1,acumulated_energy_db.shape[0]-2):\n",
    "        smooth_energy_db[j] = (acumulated_energy_db[j-1] + acumulated_energy_db[j] + acumulated_energy_db[j+1]) / 3\n",
    "        \n",
    "    # Generate a matrix [0,1] for frames with an accumulated energy above (Max - threshold)\n",
    "    treshold_db = 2000\n",
    "    max_smooth_energy_db = smooth_energy_db.max(axis=0)\n",
    "    frame_bin = np.zeros((smooth_energy_db.shape))\n",
    "    for j in range (0, acumulated_energy_db.shape[0]):\n",
    "        frame_bin[j] = np.where(smooth_energy_db[j] > max_smooth_energy_db - treshold_db, 1, 0)\n",
    "        \n",
    "    # Make zero the frames below the threshold\n",
    "    zxx_bin = np.repeat(np.expand_dims(frame_bin, axis=0), 257, 0)\n",
    "    noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi = frequency_independent_normalization(sample_number)\n",
    "    vad_clean_speech_normalized_fi = clean_speech_normalized_fi * zxx_bin\n",
    "    \n",
    "    return(vad_clean_speech_normalized_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_input_matrixes(sample_number, segment_frames_lenght):\n",
    "    # Adjust the noisy speech matrix size to input it in the network\n",
    "    # batch_size: number or audios in a training mini-batch\n",
    "    # sample_number: number of the first audio sample used in the batch\n",
    "    # segment_frames_lenght: number of past frames used for the training (160 if ) \n",
    "    \n",
    "    noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi = frequency_independent_normalization(sample_number)\n",
    "    vad_clean_speech_normalized = vad(sample_number)\n",
    "                                      \n",
    "    number_of_frames = noisy_speech_normalized_fi.shape[1]\n",
    "    dim1 = noisy_speech_normalized_fi.shape[1]-segment_frames_lenght\n",
    "    dim2 = segment_frames_lenght\n",
    "    dim3 = noisy_speech_normalized_fi.shape[0]\n",
    "    network_noisy_speech_input = np.zeros((dim1,dim2,dim3), complex)\n",
    "    network_clean_speech_input = np.zeros((dim1,dim2,dim3), complex)\n",
    "    network_vad_clean_speech_input = np.zeros((dim1,dim2,dim3), complex)\n",
    "    \n",
    "    for j in range(number_of_frames-segment_frames_lenght):\n",
    "        for k in range(segment_frames_lenght):\n",
    "            network_noisy_speech_input[j,k,:] = noisy_speech_normalized_fi[:,k+j]\n",
    "            network_clean_speech_input[j,k,:] = clean_speech_normalized_fi[:,k+j]\n",
    "            network_vad_clean_speech_input[j,k,:] = vad_clean_speech_normalized[:,k+j]\n",
    "             \n",
    "    return(network_noisy_speech_input,network_clean_speech_input, network_vad_clean_speech_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy, clean, clean_vad = adjusted_input_matrixes(100, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 160, 257)\n",
      "(224, 257)\n",
      "(224, 257)\n"
     ]
    }
   ],
   "source": [
    "#Fix dimensions\n",
    "clean = clean[:,-1,:].reshape((clean.shape[0], clean.shape[2]))\n",
    "clean_vad = clean_vad[:,-1,:].reshape((clean_vad.shape[0], clean_vad.shape[2]))\n",
    "\n",
    "#Fix batch multiplicy\n",
    "batch_size = 32\n",
    "number_batches = math.floor(len(noisy)/batch_size)\n",
    "number_samples = batch_size*number_batches\n",
    "noisy = noisy[:number_samples,:,:]\n",
    "clean = clean[:number_samples,:]\n",
    "clean_vad = clean_vad[:number_samples,:]\n",
    "\n",
    "print(noisy.shape)\n",
    "print(clean.shape)\n",
    "print(clean_vad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.convert_to_tensor(noisy, np.complex64)\n",
    "labels = tf.convert_to_tensor(clean, np.complex64)\n",
    "side_input = tf.convert_to_tensor(clean_vad, np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "\n",
    "noisy_speech = layers.Input(shape=(160,257))\n",
    "noisy_speech_current = layers.Reshape((257,), input_shape=(1,257))(noisy_speech[:,-1,:])\n",
    "clean_speech = layers.Input(shape=(257))\n",
    "vad_clean_speech = layers.Input(shape=(257))\n",
    "\n",
    "gru1 = layers.GRU(257, batch_input_shape=(160,257), return_sequences=True)(noisy_speech)\n",
    "gru1_red = layers.add([noisy_speech, gru1])\n",
    "gru2 = layers.GRU(257, batch_input_shape=(160,257), return_sequences=True)(gru1_red)\n",
    "gru2_red = layers.add([gru2, gru1_red])\n",
    "gru3 = layers.GRU(257, batch_input_shape=(160, 257), return_sequences=False)(gru2_red)\n",
    "gain = layers.Dense(257, activation='sigmoid')(gru3)\n",
    "\n",
    "model = tf.keras.Model(inputs=[noisy_speech, clean_speech, vad_clean_speech], outputs=gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.35\n",
    "loss = alpha * K.mean(K.square(vad_clean_speech-vad_clean_speech*gain), axis=-1) + (1-alpha) * K.mean(K.square((noisy_speech_current-clean_speech)*gain), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output dense_4 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_4.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples\n",
      "224/224 [==============================] - 29s 129ms/sample - loss: 0.0248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ba40cbe48>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([data, labels, side_input]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

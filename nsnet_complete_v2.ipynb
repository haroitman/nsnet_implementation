{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras.backend as K\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas import DataFrame\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean speech, Noise and Noisy speech training files\n",
    "# Count how many samples of Clean speech are used for training and how many snr levels, \n",
    "# there are snr levels of Noise and Noisy speech for every Clean speech audio\n",
    "clean_speech_list = [f for f in listdir(\"CleanSpeech_training/\") if isfile(join(\"CleanSpeech_training/\", f))]\n",
    "noise_list = [f for f in listdir(\"Noise_training/\") if isfile(join(\"Noise_training/\", f))]\n",
    "noisy_speech_list = [f for f in listdir(\"NoisySpeech_training/\") if isfile(join(\"NoisySpeech_training/\", f))]\n",
    "samples = len(clean_speech_list)\n",
    "snr_levels = len(noisy_speech_list) / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16KHz audios assumed\n",
    "frames_per_sec = 32           # Number of frames per second\n",
    "sample_length = 30            # Sample length in seconds\n",
    "segment_length = 5            # Audio segment length in seconds considered in the network training   \n",
    "wave_max_length = 600000      # Number larger than the longest audio wave \n",
    "frames_per_sample = frames_per_sec * sample_length \n",
    "segment_frames_lenght = segment_length * frames_per_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick randonmly one of the snr level of the Noise and Noisy speech samples \n",
    "from random import seed\n",
    "from random import randint\n",
    "seed(1)\n",
    "random_snr = np.random.randint(1, snr_levels+1, size=samples)\n",
    "for i in range(samples):\n",
    "    random_snr[i] = random_snr[i] + ((i) * snr_levels)\n",
    "random_snr = random_snr - 1\n",
    "random_snr = random_snr.astype(np.int64)\n",
    "\n",
    "rand_noisy_speech_list = list(noisy_speech_list[i] for i in random_snr)\n",
    "rand_noise_list = list(noise_list[i] for i in random_snr)\n",
    "noisy_speech_df = DataFrame(rand_noisy_speech_list,columns=['Sample'])\n",
    "noise_df = DataFrame(rand_noise_list,columns=['Sample'])\n",
    "clean_speech_df = DataFrame(clean_speech_list, columns=[\"Sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: noisy10_SNRdb_20.0_clnsp10.wav \n",
    "# List maximum possible elements is 99,999  \n",
    "noisy_speech_aux_list = [x[-9:-4] for x in noisy_speech_df[\"Sample\"]]\n",
    "sample_column = noisy_speech_aux_list\n",
    "for i in range(len(noisy_speech_aux_list)):\n",
    "    try:\n",
    "        sample_column[i] = int(noisy_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            sample_column[i] = int(noisy_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                sample_column[i] = int(noisy_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    sample_column[i] = int(noisy_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        sample_column[i] = int(noisy_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the df by sample_column number\n",
    "# Noise has the same file formatting than Noisy speech so it is sorted using the same df column\n",
    "noisy_speech_df[\"Sample_Number\"] = sample_column\n",
    "noise_df[\"Sample_Number\"] = sample_column\n",
    "noisy_speech_df.sort_values(by=['Sample_Number'], inplace=True)\n",
    "noise_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: clnsp1.wav\n",
    "# List maximum possible elements is 99,999\n",
    "clean_speech_aux_list = [x[-9:-4] for x in clean_speech_df[\"Sample\"]]\n",
    "clean_speach_sample_number = clean_speech_aux_list\n",
    "for i in range(len(clean_speech_aux_list)):\n",
    "    try:\n",
    "        clean_speach_sample_number[i] = int(clean_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order clean speech df by sample_column number\n",
    "clean_speech_df[\"Sample_Number\"] = clean_speach_sample_number\n",
    "clean_speech_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lists based on the data frames\n",
    "clean_speech_ordered_list = clean_speech_df[\"Sample\"]\n",
    "noisy_speech_ordered_list = noisy_speech_df[\"Sample\"]\n",
    "noise_ordered_list = noise_df['Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"CleanSpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "clean_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\CleanSpeech_training\\\\'+item for item in clean_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"NoisySpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noisy_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\NoisySpeech_training\\\\'+item for item in noisy_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"Noise_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noise_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\Noise_training\\\\'+item for item in noise_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_function(audio):\n",
    "    # generate the wave of the audio sample\n",
    "    \n",
    "    wave, sr = librosa.load(audio, sr = 16000, mono = True)\n",
    "    f, t, stft  = scipy.signal.stft(wave, fs=16000, window='hamm', nperseg=512, noverlap=0.75)\n",
    "    \n",
    "    return(stft, f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_independent_normalization(sample_number):\n",
    "    # Normalize noisy speech, clean speech and noise audios based on noisy speech global mean and standard deviation \n",
    "    # frequency independent\n",
    "    \n",
    "    noisy_speech_zxx =  wave_function(noisy_speech_ordered_list[sample_number])\n",
    "    noisy_speech_zxx_mean_fi = np.mean(noisy_speech_zxx)    \n",
    "    noisy_speech_zxx_std_fi = np.std(noisy_speech_zxx)\n",
    "    noisy_speech_normalized_fi = (noisy_speech_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi\n",
    "    \n",
    "    noise_zxx = wave_function(noise_ordered_list[sample_number])\n",
    "    noise_normalized_fi = (noise_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi\n",
    "    \n",
    "    clean_speech_zxx = wave_function(clean_speech_ordered_list[sample_number])\n",
    "    clean_speech_normalized_fi = (clean_speech_zxx - noisy_speech_zxx_mean_fi) / noisy_speech_zxx_std_fi \n",
    "\n",
    "    return (noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vad(sample_number):\n",
    "    # Voice Activity Detector (VAD) based on accumulated energy (measured in db) for frequencies between 300Hz and 5000Hz\n",
    "    # Calculate acumulated energy (db) for each frame of each audio\n",
    "\n",
    "    vad_min_frequency_limit = 300\n",
    "    vad_max_frequency_limit = 5000\n",
    "    clean_speech_zxx, clean_speech_frequency, clean_speech_time = wave_function(clean_speech_ordered_list[sample_number])\n",
    "    clean_speech_zxx_db = -librosa.amplitude_to_db(np.abs(clean_speech_zxx))  # , ref=np.max\n",
    "    acumulated_energy_db = np.zeros((clean_speech_zxx.shape[1],clean_speech_zxx.shape[2]))\n",
    "    for s in range(clean_speech_frequency.shape[1]):\n",
    "        for f in range(clean_speech_frequency.shape[0]):\n",
    "            if clean_speech_frequency[f,s] > vad_min_frequency_limit and clean_speech_frequency[f,s] < vad_max_frequency_limit:\n",
    "                for j in range(clean_speech_zxx.shape[1]):\n",
    "                    acumulated_energy_db[j,s] = acumulated_energy_db[j,s] + clean_speech_zxx_db[f,j,s] \n",
    "    \n",
    "    # Smooth the acumulated energy over 3 frames\n",
    "    smooth_energy_db = np.zeros((acumulated_energy_db.shape))\n",
    "    smooth_energy_db[0,:] = acumulated_energy_db[0,:]\n",
    "    smooth_energy_db[acumulated_energy_db.shape[0]-1,:] = acumulated_energy_db[acumulated_energy_db.shape[0]-1,:]\n",
    "    for j in range(1,acumulated_energy_db.shape[0]-2):\n",
    "        smooth_energy_db[j,:] = (acumulated_energy_db[j-1,:] + acumulated_energy_db[j,:] + acumulated_energy_db[j+1,:]) / 3\n",
    "        \n",
    "    # Generate a matrix [0,1] for frames with an accumulated energy above (Max - threshold)\n",
    "    treshold_db = 1000\n",
    "    max_smooth_energy_db = smooth_energy_db.max(axis=0)\n",
    "    frame_bin = np.zeros((smooth_energy_db.shape))\n",
    "    for j in range (0, acumulated_energy_db.shape[0]):\n",
    "        frame_bin[j,:] = np.where(smooth_energy_db[j,:] > max_smooth_energy_db[:] - treshold_db, 1, 0)\n",
    "        \n",
    "    # Make zero the frames below the threshold\n",
    "    zxx_bin = np.repeat(np.expand_dims(frame_bin, axis=0), 257, 0)\n",
    "    noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi = frequency_independent_normalization(sample_number)\n",
    "    vad_clean_speech_normalized_fi = clean_speech_normalized_fi * zxx_bin\n",
    "    \n",
    "    return(vad_clean_speech_normalized_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_matrix_size(batch_size, sample_number):\n",
    "    # Adjust the noisy speech matrix size to input it in the network\n",
    "    \n",
    "    noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi = frequency_independent_normalization(sample_number)\n",
    "\n",
    "    network_noisy_speech_input = np.zeros((noisy_speech_normalized_fi.shape[0],segment_frames_lenght,number_of_audios*(noisy_speech_normalized_fi.shape[1]-segment_frames_lenght)), complex)\n",
    "\n",
    "    # noisy_speech_normalized_fi[2,5,1] = network_input[2,5,800]\n",
    "    for i in range(batch_size):\n",
    "        for j in range(noisy_speech_normalized_fi.shape[1]-segment_frames_lenght):\n",
    "            for fr in range(segment_frames_lenght):\n",
    "                noisy_speech_normalized_fi, clean_speech_normalized_fi, noise_normalized_fi = frequency_independent_normalization(sample_number+i)                \n",
    "                network_noisy_speech_input[:,fr,i*(noisy_speech_normalized_fi.shape[1]-segment_frames_lenght)+j] = noisy_speech_normalized_fi[:,fr+j,i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\Juan\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import scipy\n",
    "import numpy as np\n",
    "import librosa\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import keras.backend as K\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "import webrtcvad\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "\n",
    "from vad_utils import VadGenerator\n",
    "from audio_processing import AudioProcessing\n",
    "from dataset_generator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean speech, Noise and Noisy speech training files\n",
    "# Count how many samples of Clean speech are used for training and how many snr levels, \n",
    "# there are snr levels of Noise and Noisy speech for every Clean speech audio\n",
    "clean_speech_list = [f for f in listdir(\"CleanSpeech_training/\") if isfile(join(\"CleanSpeech_training/\", f))]\n",
    "noise_list = [f for f in listdir(\"Noise_training/\") if isfile(join(\"Noise_training/\", f))]\n",
    "noisy_speech_list = [f for f in listdir(\"NoisySpeech_training/\") if isfile(join(\"NoisySpeech_training/\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy speech original 3701\n",
      "noisy speech complete 3690\n",
      "clean speech original 1237\n",
      "clean speech complete 1230\n",
      "noise original 3705\n",
      "noise complete 3690\n"
     ]
    }
   ],
   "source": [
    "## Make audios set complete\n",
    "\n",
    "#Erase duplicate audios\n",
    "\n",
    "clean_speech_list_complete = [item for item in clean_speech_list if item[-5:-4].isdigit()]\n",
    "noise_list_complete = [item for item in noise_list if item[-5:-4].isdigit()]\n",
    "\n",
    "noisy_speech_list_split = [item.split('_') for item in noisy_speech_list]\n",
    "df = pd.DataFrame(noisy_speech_list_split)\n",
    "df.columns = ['noisy','type','level','clean']\n",
    "df = df[df['clean'].apply(lambda x : x[-5:-4].isdigit())]\n",
    "\n",
    "#Get the noisy audios that match with clean and noise audios\n",
    "\n",
    "df['noisy_audio'] = (df['noisy'] + '_' + df['type'] + '_' + df['level'] + '_' + df['clean']).values\n",
    "df['noise_audio'] = (df['noisy'] + '_' + df['type'] + '_' + df['level'] + '.wav').values\n",
    "\n",
    "#Get the noisy audios that have 3 times the same clean audio reference\n",
    "\n",
    "df_grouped = df.groupby(['clean']).count()\n",
    "df_count = df_grouped[df_grouped['noisy']==3]\n",
    "clean_reference = [item for item in df_count.index]\n",
    "df = df[df['clean'].isin(clean_reference)]\n",
    "noise_reference = [item for item in df['noise_audio']]\n",
    "\n",
    "#Filter noise and clean audios according to references from noisy audios\n",
    "clean_speech_list_complete = [item for item in clean_speech_list_complete if item in clean_reference]\n",
    "noise_list_complete = [item for item in noise_list_complete if item in noise_reference]\n",
    "\n",
    "noisy_speech_list_complete = (df['noisy'] + '_' + df['type'] + '_' + df['level'] + '_' + df['clean']).values\n",
    "\n",
    "#Compare original vs complete audios\n",
    "\n",
    "print('noisy speech original {}'.format(len(noisy_speech_list)))\n",
    "print('noisy speech complete {}'.format(len(noisy_speech_list_complete)))\n",
    "print('clean speech original {}'.format(len(clean_speech_list)))\n",
    "print('clean speech complete {}'.format(len(clean_speech_list_complete)))\n",
    "print('noise original {}'.format(len(noise_list)))\n",
    "print('noise complete {}'.format(len(noise_list_complete)))\n",
    "\n",
    "#Update audios\n",
    "\n",
    "clean_speech_list = clean_speech_list_complete\n",
    "noise_list = noise_list_complete\n",
    "noisy_speech_list = noisy_speech_list_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = len(clean_speech_list)\n",
    "snr_levels = len(noisy_speech_list) / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16KHz audios assumed\n",
    "frames_per_sec = 32           # Number of frames per second\n",
    "sample_length = 30            # Sample length in seconds\n",
    "segment_length = 5            # Audio segment length in seconds considered in the network training   \n",
    "wave_max_length = 600000      # Number larger than the longest audio wave \n",
    "frames_per_sample = frames_per_sec * sample_length \n",
    "segment_frames_lenght = segment_length * frames_per_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick randonmly one of the snr level of the Noise and Noisy speech samples \n",
    "from random import seed\n",
    "from random import randint\n",
    "seed(1)\n",
    "random_snr = np.random.randint(1, snr_levels+1, size=samples)\n",
    "for i in range(samples):\n",
    "    random_snr[i] = random_snr[i] + ((i) * snr_levels)\n",
    "random_snr = random_snr - 1\n",
    "random_snr = random_snr.astype(np.int64)\n",
    "\n",
    "rand_noisy_speech_list = list(noisy_speech_list[i] for i in random_snr)\n",
    "rand_noise_list = list(noise_list[i] for i in random_snr)\n",
    "noisy_speech_df = DataFrame(rand_noisy_speech_list,columns=['Sample'])\n",
    "noise_df = DataFrame(rand_noise_list,columns=['Sample'])\n",
    "clean_speech_df = DataFrame(clean_speech_list, columns=[\"Sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: noisy10_SNRdb_20.0_clnsp10.wav \n",
    "# List maximum possible elements is 99,999  \n",
    "noisy_speech_aux_list = [x[-9:-4] for x in noisy_speech_df[\"Sample\"]]\n",
    "sample_column = noisy_speech_aux_list\n",
    "for i in range(len(noisy_speech_aux_list)):\n",
    "    try:\n",
    "        sample_column[i] = int(noisy_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            sample_column[i] = int(noisy_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                sample_column[i] = int(noisy_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    sample_column[i] = int(noisy_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        sample_column[i] = int(noisy_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the df by sample_column number\n",
    "# Noise has the same file formatting than Noisy speech so it is sorted using the same df column\n",
    "noisy_speech_df[\"Sample_Number\"] = sample_column\n",
    "noise_df[\"Sample_Number\"] = sample_column\n",
    "noisy_speech_df.sort_values(by=['Sample_Number'], inplace=True)\n",
    "noise_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of integers using the last part of the file name\n",
    "# file name format: clnsp1.wav\n",
    "# List maximum possible elements is 99,999\n",
    "clean_speech_aux_list = [x[-9:-4] for x in clean_speech_df[\"Sample\"]]\n",
    "clean_speach_sample_number = clean_speech_aux_list\n",
    "for i in range(len(clean_speech_aux_list)):\n",
    "    try:\n",
    "        clean_speach_sample_number[i] = int(clean_speech_aux_list[i])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-4:])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-3:])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-2:])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        clean_speach_sample_number[i] = int(clean_speech_aux_list[i][-1:])\n",
    "                    except ValueError:\n",
    "                        \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order clean speech df by sample_column number\n",
    "clean_speech_df[\"Sample_Number\"] = clean_speach_sample_number\n",
    "clean_speech_df.sort_values(by=['Sample_Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lists based on the data frames\n",
    "clean_speech_ordered_list = clean_speech_df[\"Sample\"]\n",
    "noisy_speech_ordered_list = noisy_speech_df[\"Sample\"]\n",
    "noise_ordered_list = noise_df['Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"CleanSpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "clean_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\CleanSpeech_training\\\\'+item for item in clean_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"NoisySpeech_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noisy_speech_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\NoisySpeech_training\\\\'+item for item in noisy_speech_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio files in the list\n",
    "pathAudio = \"Noise_training/\"\n",
    "os.path.dirname(os.path.realpath(pathAudio))\n",
    "noise_ordered_list = [os.path.dirname(os.path.realpath(pathAudio))+'\\\\Noise_training\\\\'+item for item in noise_ordered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "window_lenght = 32\n",
    "\n",
    "noisy_speech = layers.Input(shape=(window_lenght,257))\n",
    "clean_speech = layers.Input(shape=(257))\n",
    "vad_clean_speech = layers.Input(shape=(257))\n",
    "noise_speech = layers.Input(shape=(257))\n",
    "noisy_speech_current = layers.Reshape((257,), input_shape=(1,257))(noisy_speech[:,-1,:])\n",
    "\n",
    "gru1 = layers.GRU(257, batch_input_shape=(window_lenght,257), return_sequences=True)(noisy_speech)\n",
    "gru1_red = layers.add([noisy_speech, gru1])\n",
    "gru2 = layers.GRU(257, batch_input_shape=(window_lenght,257), return_sequences=True)(gru1_red)\n",
    "gru2_red = layers.add([gru2, gru1_red])\n",
    "gru3 = layers.GRU(257, batch_input_shape=(window_lenght, 257), return_sequences=False)(noisy_speech)\n",
    "#dense1 = layers.Dense(257, activation='sigmoid')(gru3)\n",
    "gain = layers.Dense(257, activation='sigmoid')(gru3)\n",
    "\n",
    "model = tf.keras.Model(inputs=[noisy_speech, clean_speech, vad_clean_speech, noise_speech], outputs=gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 32, 257)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_17 (GRU)                    (None, 257)          397836      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 257)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 257)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 257)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 257)          66306       gru_17[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 464,142\n",
      "Trainable params: 464,142\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.35\n",
    "#loss = alpha * K.mean( K.sqrt( K.sum(K.square(vad_clean_speech-vad_clean_speech*gain), axis=1) ) , axis=-1) + (1-alpha) * K.mean( K.sqrt( K.sum(K.square(noise_speech*gain), axis=1)), axis=-1)\n",
    "loss = alpha * K.mean( K.square( K.abs(vad_clean_speech-vad_clean_speech*gain)), axis=-1) + (1-alpha) * K.mean(K.square(K.abs((noise_speech)*gain)), axis=-1)\n",
    "#loss = alpha * K.mean( K.square( K.abs( clean_speech-clean_speech*gain) ), axis=-1) + (1-alpha) * K.mean(K.square( K.abs( noise_speech*gain) ) , axis=-1)\n",
    "#loss = alpha * K.mean(  K.l2_normalize(clean_speech-clean_speech*gain, axis=1), axis=-1)  + (1-alpha) * K.mean( K.l2_normalize(noise_speech*gain, axis=1) , axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output dense_5 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_5.\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "sgd = optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "model.compile(optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "training_batch_generator = DatasetGenerator(clean_speech_ordered_list, noisy_speech_ordered_list, noise_ordered_list, frames_per_sec, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1200 steps\n",
      "Epoch 1/20\n",
      " 959/1200 [======================>.......] - ETA: 32s - loss: 1.2136e-06"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(generator = training_batch_generator,\n",
    "                    steps_per_epoch = int(1200 // batch_size),\n",
    "                    epochs = 20,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_audios1200_epochs60.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
